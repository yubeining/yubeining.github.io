---
title: flink
date: 2025-04-19
updated: 2025-04-19
categories: 搜推广
tags:
  - 搜推广
  - 笔记
top: 1
---

Apache Flink 是一种用于构建实时、批处理和流处理的统一架构。它采用迭代算法来实现流处理，允许用户以事件流的形式处理数据。

Flink 的基本思想是通过事件的时间戳或者在指定条件下触发一个任务，从而将这些操作组织起来形成一种有序的方式完成所有处理。这可以看作是 Flink 中的“并发”和“同步”的平衡点。

### 1. 数据流与批处理
- **数据流**：Flink 提供了事件驱动的数据流 API 来处理实时或连续发生的业务数据，而不是将整个数据集一次性加载到内存。
- **批处理**：在 Flink 中，可以处理包含大量记录的批量数据。

### 2. 迭代算法
Flink 使用迭代算法来处理流中的数据。这使得它可以有效地处理实时事件流，并支持用户自定义的过滤、聚合和排序逻辑。

### 3. 异步编程
- **异步**：在 Flink 中，处理过程是异步进行的，这意味着数据流可以以批处理的形式并行处理，而不需要等待所有的记录都到达内存。
- **事件驱动**：Flink 遵循事件驱动的设计原则，每一条经过的消息都会被转换为一个任务。

### 4. 同步与并发
- **同步**：在 Flink 中，处理过程是线程安全的，并且可以保证结果的一致性。
- **并发**：通过使用迭代算法和异步编程模式，Flink 可以支持流数据的实时处理，从而满足实时处理的需求。

### 5. 集群化与容错
- Flink 支持在分布式环境中进行大规模计算，并且提供了高可用性和容错机制。
- Flink 允许用户根据需要选择是否使用分布式环境来执行任务。

### 6. API 简介
Flink 的 API 包含了以下主要组成部分：

- **流API**：处理实时数据的事件驱动接口，包括 `StreamExecutionEnvironment`、`DataStream` 和 `SQLContext`。
- **批处理API**：处理批量数据的数据源和解析器（例如文件输入、日志输入或JSON数据）。

通过以上这些基本原理，Flink 提供了灵活且高性能的数据流处理能力。